{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRAIN TUMOR DETECTION USING DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset used : https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for extracting zip file dataset \n",
    "import zipfile\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "#for building CNN model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, MaxPooling2D,GlobalAvgPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"archive.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 files belonging to 4 classes.\n",
      "Found 2870 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test=image_dataset_from_directory(\"Testing\",label_mode=\"categorical\",image_size=(300,300),batch_size=100)\n",
    "train=image_dataset_from_directory(\"Training\",label_mode=\"categorical\",image_size=(300,300),batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 289, 289, 36)      15588     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 284, 284, 64)      83008     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 142, 142, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 139, 139, 128)     131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 69, 69, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 67, 67, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 33, 33, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 33, 33, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 278784)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               27878500  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 40)                4040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 28,407,668\n",
      "Trainable params: 28,407,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(36,(12,12), activation='relu', input_shape = (300,300,3)))\n",
    "\n",
    "model.add(Conv2D(64,(6,6), activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(4,4), activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3), activation='relu' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units= 100, activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(units= 4, activation='softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.binary_crossentropy, optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing our data using data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    zoom_range = 0.2, shear_range = 0.2, rescale = 1./255, horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(directory='Training', target_size= (300,300), batch_size=64,\n",
    "class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = train_datagen.flow_from_directory(directory='Testing', target_size= (300,300,3), batch_size=64,\n",
    "class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping and Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#early stopping\n",
    "es = EarlyStopping(monitor = 'accuracy', min_delta = 0.01, patience = 5, verbose = 1, mode = 'auto')\n",
    "\n",
    "#model checkpoint\n",
    "mc = ModelCheckpoint(filepath = \"best_model.h5\", monitor = 'accuracy', verbose = 1, save_best_only = True, mode = 'auto')\n",
    "\n",
    "# putting call back in a list\n",
    "call_back = [es , mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "29/29 [==============================] - 1383s 48s/step - loss: 0.1983 - accuracy: 0.8568 - val_loss: 0.7610 - val_accuracy: 0.6142\n",
      "\n",
      "Epoch 00001: accuracy improved from 0.82979 to 0.85679, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 1377s 48s/step - loss: 0.1337 - accuracy: 0.9125 - val_loss: 0.7275 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.85679 to 0.91254, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 1378s 48s/step - loss: 0.0896 - accuracy: 0.9460 - val_loss: 0.8461 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.91254 to 0.94599, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 1378s 48s/step - loss: 0.0616 - accuracy: 0.9683 - val_loss: 1.1662 - val_accuracy: 0.7056\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.94599 to 0.96829, saving model to best_model.h5\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 1380s 48s/step - loss: 0.0491 - accuracy: 0.9756 - val_loss: 1.1393 - val_accuracy: 0.7234\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.96829 to 0.97561, saving model to best_model.h5\n",
      "Epoch 6/15\n",
      "29/29 [==============================] - 1380s 48s/step - loss: 0.0405 - accuracy: 0.9805 - val_loss: 0.9112 - val_accuracy: 0.7259\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.97561 to 0.98049, saving model to best_model.h5\n",
      "Epoch 7/15\n",
      "29/29 [==============================] - 1384s 48s/step - loss: 0.0308 - accuracy: 0.9868 - val_loss: 1.1248 - val_accuracy: 0.7005\n",
      "\n",
      "Epoch 00007: accuracy improved from 0.98049 to 0.98676, saving model to best_model.h5\n",
      "Epoch 8/15\n",
      "29/29 [==============================] - 1391s 48s/step - loss: 0.0255 - accuracy: 0.9902 - val_loss: 1.3549 - val_accuracy: 0.7259\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.98676 to 0.99024, saving model to best_model.h5\n",
      "Epoch 9/15\n",
      "29/29 [==============================] - 1410s 49s/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 1.2936 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.99024 to 0.99199, saving model to best_model.h5\n",
      "Epoch 10/15\n",
      "29/29 [==============================] - 1408s 49s/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 1.3379 - val_accuracy: 0.7386\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.99199 to 0.99617, saving model to best_model.h5\n",
      "Epoch 11/15\n",
      "29/29 [==============================] - 1409s 49s/step - loss: 0.0151 - accuracy: 0.9923 - val_loss: 1.4070 - val_accuracy: 0.7335\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.99617\n",
      "Epoch 12/15\n",
      "29/29 [==============================] - 1417s 49s/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 1.6850 - val_accuracy: 0.7437\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.99617\n",
      "Epoch 13/15\n",
      "29/29 [==============================] - 1402s 48s/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 1.1428 - val_accuracy: 0.7335\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.99617\n",
      "Epoch 14/15\n",
      "29/29 [==============================] - 1157s 40s/step - loss: 0.0227 - accuracy: 0.9899 - val_loss: 1.3502 - val_accuracy: 0.7259\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.99617\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator= train , \n",
    "epochs = 15, \n",
    "validation_data = test,\n",
    "callbacks = call_back)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cc299e930bd8a7046fb8f368401782c8f27bc73a171425b9b20909118cbdf22"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
